{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of UNET performance upon common distortions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to provide some informations about how a UNET initially trained to segment cells is perturbated by some common distortions applied on the input images. The tested distortions applied on the inputs are an added 2D gaussian, a gaussian noise as well as a rescaling of the input images. To evaluate the performance of the UNET, several plots are generated: the accuracy, the Jaccard index and the number of detected cells in function of the degree of degradation that depends on the parameters of the distortions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\bullet$ Importing libraries and utilitary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1491,
     "status": "ok",
     "timestamp": 1605116259220,
     "user": {
      "displayName": "EPFLML2020 GoodLastName",
      "photoUrl": "",
      "userId": "08441615881122576683"
     },
     "user_tz": -60
    },
    "id": "T3d4FS-rUEiK",
    "outputId": "302be8e3-c259-4739-8108-501a318136cd"
   },
   "outputs": [],
   "source": [
    "# Import python libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow\n",
    "\n",
    "# Import distortion filters and utilitary functions.\n",
    "from distortions import add_gaussian, zoom_image, zoom_image_to_meet_shape, add_gaussian_noise\n",
    "from utils import *\n",
    "from image_processing_methods import DogImageProcessingMethod, DenoiserImageProcessingMethod\n",
    "from plots import show_image_mask, show_image_pred, plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds of random number generators to guarantee reproducibility.\n",
    "np.random.seed(3)\n",
    "tensorflow.random.set_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\bullet$ Setting size of the input image and different paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "executionInfo": {
     "elapsed": 3866,
     "status": "ok",
     "timestamp": 1605116263978,
     "user": {
      "displayName": "EPFLML2020 GoodLastName",
      "photoUrl": "",
      "userId": "08441615881122576683"
     },
     "user_tz": -60
    },
    "id": "oFUJJMwMalBG"
   },
   "outputs": [],
   "source": [
    "# Shape of the inputs of the deep network.\n",
    "images_shape = (256, 256, 1)\n",
    "\n",
    "# Variables defining the path to the dataset.\n",
    "test_input_path  = '../Dataset/test/input/'\n",
    "test_output_path = '../Dataset/test/output/'\n",
    "\n",
    "# Variable defining where models are stored.\n",
    "unet_original_save_path       = \"../Models/Unet Original/\"\n",
    "unet_data_augmented_save_path = \"../Models/Unet Data Augmented/\"\n",
    "unet_data_distorted_save_path = \"../Models/Unet Data Distorted/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\bullet$ Function to display the input images and predictions upon distorsion as well as a summary of values that shows the quality of the predicted images compared to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "b72u9_VE31H2"
   },
   "outputs": [],
   "source": [
    "def evaluation_summary(result, parameter_name, parameter_val, image, mask, distorted_image, models):\n",
    "    \"\"\"\n",
    "    Function printing a summary of the results collected in results and showing exemples of the original \n",
    "    image and mask, distorted images, and predictions of each model.\n",
    "    \n",
    "    Args:\n",
    "        result::[dict]\n",
    "            Dictionary with the name of the model as key and as value another dictionary with keys\n",
    "            the computed metrics for the predictions by the respective model.\n",
    "        parameter_name::[string]\n",
    "            The name of the parameter that was being tested when collecting result. Only needed to print\n",
    "            it next to its value for reference.\n",
    "        parameter_val::[float]\n",
    "            value taken by the parameter that was being tested when collecting result. Only needed to print\n",
    "            it in the summary for reference.\n",
    "        image::[np.array]\n",
    "            Numpy array of shape (n_lines, n_columns, n_channels) representing one image sampled from the\n",
    "            images used to collect result that is shown as to the user as an exemple.\n",
    "        mask::[np.array]\n",
    "            Numpy array of same shape as image containing the corresponding true segmentation mask, used\n",
    "            to display as an exemple. \n",
    "        distorted_image::[np.array]\n",
    "            Numpy array of same shape as image containing the corresponding distorted image used for prediction,\n",
    "            used to display as an exemple.  \n",
    "        models::[dict]\n",
    "            Dictionary with the name of the model as key and as value an object implementing a predict method\n",
    "            as required by utils.get_binary_predictions.\n",
    "            \n",
    "    \"\"\"\n",
    "    print(\"{:<50}: {}\".format(parameter_name.upper()          , parameter_val))\n",
    "    for model_key in result.keys():\n",
    "        print(\"{}\".format(model_key.upper()))\n",
    "        print(\"     {:<45}: {}\".format(\"Accuracy\"                      , result[model_key][\"accuracy\"]))\n",
    "        print(\"     {:<45}: {}\".format(\"Jaccard score\"                 , result[model_key][\"jaccard\"]))\n",
    "        print(\"     {:<45}: {}\".format(\"Precision\"                     , result[model_key][\"precision\"]))\n",
    "        print(\"     {:<45}: {}\".format(\"Recall\"                        , result[model_key][\"recall\"]))\n",
    "        print(\"     {:<45}: {}\".format(\"Number of cells in predictions\", result[model_key][\"number_cells_predictions\"]))\n",
    "        print(\"     {:<45}: {}\".format(\"Number of cells in masks\"      , result[model_key][\"number_cells_masks\"]))\n",
    "        \n",
    "    show_image_mask(image, mask)\n",
    "    show_image_pred(distorted_image, models)\n",
    "    \n",
    "    \n",
    "def evaluate_models(images, masks, models, number_cells_masks=None):\n",
    "    \"\"\"\n",
    "    Function calculating the predicted binary segmentation masks for each model in models and from those\n",
    "    computing the different metrics used to evaluate the models, collected in a dictionary with the name\n",
    "    of the model as key and as value another dictionary collecting the computed metrics for the respective\n",
    "    model.\n",
    "    \n",
    "    Args:\n",
    "        images::[np.array]\n",
    "            Numpy array of shape (n_images, n_lines, n_columns, n_channels) containing the images to segment.\n",
    "        masks::[np.array]\n",
    "            Numpy array of same shape as images containing the true segmentation masks corresponding to images.\n",
    "        models::[dict]\n",
    "            Dictionary with the name of the model as key and as value an object implementing a predict method\n",
    "            as required by utils.get_binary_predictions.\n",
    "        number_cells_masks::[int]\n",
    "            The total number of cells contained in all the masks. If None, it is computed from masks.\n",
    "            \n",
    "    Returns:\n",
    "        results_each_model::[dict]\n",
    "            Dictionary with the name of the model as key and as value another dictionary with keys\n",
    "            the computed metrics for the predictions by the respective model.\n",
    "    \n",
    "    \"\"\"\n",
    "    results_each_model = {}\n",
    "    for key, model in models.items():\n",
    "        predictions = get_binary_predictions(images, model)\n",
    "        accuracy    = np.mean(predictions == masks)\n",
    "        jaccard     = compute_jaccard_score(predictions, masks)\n",
    "        precision, recall = compute_precision_recall(predictions, masks)\n",
    "        \n",
    "        number_cells_predictions = get_number_cells(predictions)\n",
    "        if number_cells_masks is None:\n",
    "            number_cells_masks = get_number_cells(masks)\n",
    "        \n",
    "        results_each_model[key] = {\"accuracy\": accuracy, \"jaccard\": jaccard, \"precision\": precision, \n",
    "                                   \"recall\": recall, \"number_cells_predictions\": number_cells_predictions,\n",
    "                                   \"number_cells_masks\": number_cells_masks}\n",
    "    \n",
    "    return results_each_model\n",
    "\n",
    "\n",
    "def apply_distortion_to_all(function, images, params_for_images={}):\n",
    "    \"\"\"\n",
    "    Function applying the distortion in function parameter on all images using the parameters\n",
    "    passed params_for_images.\n",
    "    \n",
    "    Args:\n",
    "        function::[function]\n",
    "            Function accepting kwargs in params_for_images which is going to be applied to each image in images.\n",
    "        images::[np.array]\n",
    "            Numpy array of shape (n_images, n_lines, n_columns, n_channels) containing the images to apply the\n",
    "            distortion onto.\n",
    "        params_for_images::[dict]\n",
    "            Dictionary containing the kwargs needed to call function parameter.\n",
    "            \n",
    "    Returns:\n",
    "        distorted_images::[np.array]]\n",
    "            Numpy array of same shape as images containing the images on which the distortion was applied.\n",
    "    \n",
    "    \"\"\"\n",
    "    distorted_images = []\n",
    "    for image in images:\n",
    "        distorted_images.append(function(image, **params_for_images))\n",
    "    \n",
    "    return np.array(distorted_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\bullet$ Retrieve trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models[\"unet original\"]       = tensorflow.keras.models.load_model(unet_original_save_path)\n",
    "models[\"unet data augmented\"] = tensorflow.keras.models.load_model(unet_data_augmented_save_path)\n",
    "models[\"unet data distorted\"] = tensorflow.keras.models.load_model(unet_data_distorted_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\bullet$ Load images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7175,
     "status": "ok",
     "timestamp": 1605116267655,
     "user": {
      "displayName": "EPFLML2020 GoodLastName",
      "photoUrl": "",
      "userId": "08441615881122576683"
     },
     "user_tz": -60
    },
    "id": "5kRpcG_R9SvH",
    "outputId": "0f533a82-ba05-4b2a-d4c8-eeb691e26ae0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set contains 510 images of shape (256, 256, 1).\n",
      "16183 cells were counted in total over all masks.\n"
     ]
    }
   ],
   "source": [
    "test_images, test_masks = get_dataset_from_folders(test_input_path, test_output_path, images_shape)\n",
    "\n",
    "print(f'Test set contains {len(test_images)} images of shape {test_images[0].shape}.')\n",
    "\n",
    "number_cells_masks = get_number_cells(test_masks)\n",
    "print(f\"{number_cells_masks} cells were counted in total over all masks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\bullet$ Analysis of the perturbations caused by an added gaussian on the UNET performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ecdf21277a7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0madded_gaussian_test_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_distortion_to_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_gaussian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"amplitude\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mamplitude\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madded_gaussian_test_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels_added_gaussian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_cells_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mamplitude\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-d51680f7018d>\u001b[0m in \u001b[0;36mevaluate_models\u001b[1;34m(images, masks, models, number_cells_masks)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_binary_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0maccuracy\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mjaccard\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mcompute_jaccard_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_precision_recall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   3371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3372\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[1;32m-> 3373\u001b[1;33m                           out=out, **kwargs)\n\u001b[0m\u001b[0;32m   3374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         ret = um.true_divide(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameter_name = \"Amplitude of Gaussian (Before Normalization)\"\n",
    "\n",
    "models_added_gaussian = models.copy()\n",
    "models_added_gaussian[\"image processing method\"] = DogImageProcessingMethod(ksize_low = 20)\n",
    "\n",
    "amplitudes = np.linspace(0, 4000, 41)\n",
    "results = {}\n",
    "\n",
    "for amplitude in amplitudes:\n",
    "    added_gaussian_test_images = apply_distortion_to_all(add_gaussian, test_images, {\"amplitude\": amplitude})\n",
    "    \n",
    "    result = evaluate_models(added_gaussian_test_images, test_masks, models_added_gaussian, number_cells_masks)\n",
    "    results[amplitude] = result\n",
    "    \n",
    "    evaluation_summary(result, parameter_name, amplitude, test_images[0], test_masks[0], \n",
    "                       added_gaussian_test_images[0], models_added_gaussian)\n",
    "    \n",
    "plot_results(results, parameter_name, models_added_gaussian.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\bullet$ Analysis of the perturbations caused by a gaussian noise on the UNET performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameter_name = \"Standard Deviation\"\n",
    "\n",
    "models_noisy = models.copy()\n",
    "models_noisy[\"image processing method\"] = DenoiserImageProcessingMethod(denoiser_strength = 25)\n",
    "\n",
    "mean = 0\n",
    "sigmas = np.linspace(0, 200, 41)\n",
    "results = {}\n",
    "\n",
    "for sigma in sigmas:\n",
    "    noisy_test_images = apply_distortion_to_all(add_gaussian_noise, test_images, {\"mean\": mean, \"sigma\": sigma})\n",
    "\n",
    "    result = evaluate_models(noisy_test_images, test_masks, models_noisy, number_cells_masks)\n",
    "    results[sigma] = result\n",
    "    \n",
    "    evaluation_summary(result, parameter_name, sigma, test_images[0], test_masks[0], noisy_test_images[0], models_noisy)\n",
    "        \n",
    "plot_results(results, parameter_name, models_noisy.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\bullet$ Analysis of the perturbations caused by a rescaling of the images on the UNET performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_name = \"Zooming Factor from Patches\"\n",
    "\n",
    "zooms = np.r_[np.linspace(0.5, 2, 15, endpoint=False), np.linspace(2, 5, 7)]\n",
    "results = {}\n",
    "\n",
    "for zoom in zooms:\n",
    "    zoomed_test_images = apply_distortion_to_all(zoom_image, test_images, {\"zoom_factor\": zoom})\n",
    "    zoomed_test_masks  = apply_distortion_to_all(zoom_image, test_masks , {\"zoom_factor\": zoom, \"val_padding\": 0})\n",
    "\n",
    "    result = evaluate_models(zoomed_test_images, zoomed_test_masks, models)\n",
    "    results[zoom] = result\n",
    "    \n",
    "    evaluation_summary(result, parameter_name, zoom, zoomed_test_images[0], zoomed_test_masks[0], zoomed_test_images[0], models)\n",
    "    \n",
    "plot_results(results, parameter_name, models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\bullet$ Get full input images from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full_images, test_full_masks = get_dataset_from_folders(test_input_path, test_output_path)\n",
    "full_images_shape = (*test_full_images[0].shape, 1)\n",
    "\n",
    "print(f'Test set contains {len(test_full_images)} images of shape {full_images_shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\bullet$ Analysis of the perturbations caused by havind different sizes of cells on the UNET performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_name = \"Zooming Factor from Original Images\"\n",
    "\n",
    "zooms = np.r_[np.linspace(0.5, 2, 15, endpoint=False), np.linspace(2, 5, 7)]\n",
    "results = {}\n",
    "\n",
    "for zoom in zooms:\n",
    "    patch_shape = (int(images_shape[0] / zoom), int(images_shape[1] / zoom), 1)\n",
    "    n_patches = np.clip(np.prod(np.divide(full_images_shape, patch_shape)), 6, 80).astype('uint')\n",
    "    patch_images, patch_masks = split_images_and_masks_into_patches(test_full_images, test_full_masks, patch_shape, n_patches)\n",
    "    \n",
    "    zoomed_test_images = apply_distortion_to_all(zoom_image_to_meet_shape, patch_images, {\"shape\": images_shape})\n",
    "    zoomed_test_masks  = apply_distortion_to_all(zoom_image_to_meet_shape, patch_masks , {\"shape\": images_shape})\n",
    "\n",
    "    result = evaluate_models(zoomed_test_images, zoomed_test_masks, models)\n",
    "    results[zoom] = result\n",
    "    \n",
    "    evaluation_summary(result, parameter_name, zoom, zoomed_test_images[0], zoomed_test_masks[0], zoomed_test_images[0], models)\n",
    "    \n",
    "plot_results(results, parameter_name, models.keys())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "UNET Distortion.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
